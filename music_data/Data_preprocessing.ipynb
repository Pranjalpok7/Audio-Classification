{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "24c9663a-0150-49fe-881e-1f75b3be7c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def rename_files_in_directory(directory):\n",
    "    \"\"\"\n",
    "    Renames files in the specified directory to follow the format: song_001.wav, song_002.wav, etc.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Path to the directory containing files to rename.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"The directory '{directory}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "    files.sort()  # Sort files to ensure consistent numbering\n",
    "\n",
    "    for index, filename in enumerate(files, start=1):\n",
    "        old_file_path = os.path.join(directory, filename)\n",
    "        \n",
    "        # Define new file name\n",
    "        new_name = f\"Tamangs_train{index:03d}.wav\"\n",
    "        new_file_path = os.path.join(directory, new_name)\n",
    "\n",
    "        # Rename file\n",
    "        try:\n",
    "            os.rename(old_file_path, new_file_path)\n",
    "            print(f\"Renamed: {filename} -> {new_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to rename '{filename}': {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "49172b24-319c-4fdc-ab20-0260910d6fc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# User-defined settings\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     directory_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the directory path: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m      4\u001b[0m     rename_files_in_directory(directory_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/semproject/lib/python3.11/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[1;32m   1283\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[1;32m   1284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1285\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1286\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1287\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/semproject/lib/python3.11/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # User-defined settings\n",
    "    directory_path = input(\"Enter the directory path: \").strip()\n",
    "    rename_files_in_directory(directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "155405f4-7159-4c05-9249-97553755ecb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration\n",
    "dataset_root = \"Audio_dataset/Train\"  # Root directory containing class folders\n",
    "output_csv = \"nepali_music_metadata.csv\"\n",
    "num_folds = 10\n",
    "random_seed = 42\n",
    "\n",
    "# Collect file information\n",
    "file_paths = []\n",
    "class_names = []\n",
    "\n",
    "# Walk through class directories\n",
    "for class_dir in Path(dataset_root).iterdir():\n",
    "    if class_dir.is_dir():\n",
    "        class_name = class_dir.name  # e.g. \"sakela\", \"deuda\"\n",
    "        for audio_file in class_dir.glob(\"*.wav\"):\n",
    "            file_paths.append(str(audio_file))\n",
    "            class_names.append(class_name)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"file_path\": file_paths,\n",
    "    \"class_name\": class_names\n",
    "})\n",
    "\n",
    "# Add numeric class IDs\n",
    "df[\"class_id\"] = df[\"class_name\"].astype(\"category\").cat.codes\n",
    "\n",
    "# Create stratified folds\n",
    "skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=random_seed)\n",
    "df[\"fold\"] = -1  # Initialize fold column\n",
    "\n",
    "for fold_idx, (_, test_idx) in enumerate(skf.split(df, df[\"class_id\"])):\n",
    "    df.iloc[test_idx, df.columns.get_loc(\"fold\")] = fold_idx + 1  # Folds 1-10\n",
    "\n",
    "# Save metadata\n",
    "df.to_csv(output_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4460b1dc-90a8-4ee6-83da-bf752e29a8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall class distribution:\n",
      "class_name\n",
      "jhyaure                    818\n",
      "asare                      810\n",
      "tharu                      807\n",
      "Deuda                      804\n",
      "Maruni                     800\n",
      "Kumari                     800\n",
      "sakela                     800\n",
      "Salaijo                    800\n",
      "Sarangi Gandharva songs    800\n",
      "Tamangs                    798\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution across folds\n",
    "print(\"Overall class distribution:\")\n",
    "print(df[\"class_name\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "05630bf9-6984-4f31-851f-5d0b50b81fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import resampy\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow_hub as hub\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "837d02ae-f246-4edf-ab37-a05db23b9711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_aligned(wav_root_dir, metadata_csv_path, output_h5_path):\n",
    "    \"\"\"Extract YamNet features in EXACT metadata CSV order\"\"\"\n",
    "    # Load metadata and sort by file_path to ensure alignment\n",
    "    metadata = pd.read_csv(metadata_csv_path).sort_values('file_path')\n",
    "    \n",
    "    # Load YamNet model\n",
    "    model = hub.load('https://tfhub.dev/google/yamnet/1')\n",
    "    \n",
    "    # Initialize storage in METADATA ORDER\n",
    "    features = []\n",
    "    labels = []\n",
    "    failed_files = []\n",
    "\n",
    "    # Process files in EXACT CSV ORDER\n",
    "    for idx, row in tqdm(metadata.iterrows(), total=len(metadata), desc='Processing audio'):\n",
    "        file_path = row['file_path']\n",
    "        class_id = row['class_id']\n",
    "        \n",
    "        try:\n",
    "            # Load and resample with librosa (handles various formats)\n",
    "            audio, sr = librosa.load(file_path, sr=None, mono=True)\n",
    "            if sr != 16000:\n",
    "                audio = resampy.resample(audio, sr, 16000)\n",
    "            \n",
    "            # Extract YamNet embeddings\n",
    "            _, embeddings, _ = model(audio)\n",
    "            \n",
    "            # Temporal average pooling (maintain 1024D)\n",
    "            features.append(np.mean(embeddings.numpy(), axis=0).astype(np.float32))\n",
    "            labels.append(int(class_id))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {str(e)}\")\n",
    "            failed_files.append(file_path)\n",
    "            continue\n",
    "\n",
    "    # Convert to aligned numpy arrays\n",
    "    features_array = np.array(features, dtype=np.float32)\n",
    "    labels_array = np.array(labels, dtype=np.int64)\n",
    "\n",
    "    # Save with h5py in METADATA ORDER\n",
    "    with h5py.File(output_h5_path, 'w') as hf:\n",
    "        hf.create_dataset('features', data=features_array)\n",
    "        hf.create_dataset('labels', data=labels_array)\n",
    "        \n",
    "    # Save list of failed files\n",
    "    if failed_files:\n",
    "        with open('failed_files.txt', 'w') as f:\n",
    "            f.write('\\n'.join(failed_files))\n",
    "        print(f\"{len(failed_files)} files failed processing. See failed_files.txt\")\n",
    "\n",
    "    return features_array.shape, labels_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "06306c0e-3196-4418-900c-434fffb7e01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio: 100%|███████████████████| 8037/8037 [1:02:46<00:00,  2.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((8037, 1024), (8037,))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_features_aligned(\n",
    "    wav_root_dir=\"Audio_dataset/Train\",\n",
    "    metadata_csv_path=\"nepali_music_metadata.csv\", \n",
    "    output_h5_path=\"nepali_features.hdf5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "62a73bfe-fda5-4858-973b-84aa42fac14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files aligned correctly!\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(output_csv).sort_values(\"file_path\")\n",
    "with h5py.File('nepali_features.hdf5', 'r') as hf:\n",
    "    hdf5_labels = hf[\"labels\"][:]\n",
    "    hdf5_features = hf[\"features\"][:]\n",
    "\n",
    "# Check random samples\n",
    "for _ in range(8038):\n",
    "    idx = np.random.randint(0, len(df))\n",
    "    csv_class = df.iloc[idx][\"class_id\"]\n",
    "    hdf5_class = hdf5_labels[idx]\n",
    "    \n",
    "    assert csv_class == hdf5_class, \\\n",
    "        f\"Mismatch at index {idx}: CSV={csv_class}, HDF5={hdf5_class}\"\n",
    "\n",
    "print(\"All files aligned correctly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "96d728ab-b2dd-4290-a4fa-0ca912708b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      "//features\n",
      "    Dataset shape: (8037, 1024), dtype: float32\n",
      "//labels\n",
      "    Dataset shape: (8037,), dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "# Replace 'your_file.hdf5' with the path to your HDF5 file\n",
    "file_path = 'nepali_features.hdf5'\n",
    "\n",
    "# Open the HDF5 file\n",
    "with h5py.File(file_path, 'r') as f:\n",
    "    # Function to recursively print the structure\n",
    "    def print_structure(name, obj):\n",
    "        print(name)\n",
    "        if isinstance(obj, h5py.Group):\n",
    "            for key in obj.keys():\n",
    "                print_structure(f\"{name}/{key}\", obj[key])\n",
    "        elif isinstance(obj, h5py.Dataset):\n",
    "            print(f\"    Dataset shape: {obj.shape}, dtype: {obj.dtype}\")\n",
    "\n",
    "    # Start printing the structure from the root\n",
    "    print_structure('/', f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1d221d-1ee2-444a-9c34-7a69a9ddbb8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
